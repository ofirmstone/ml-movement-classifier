{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "SEED = 1350\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "GESTURES = [\n",
        "    \"running\",\n",
        "    \"walking\",\n",
        "    'idle'\n",
        "]\n",
        "\n",
        "SAMPLES_PER_GESTURE = 125\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "  gesture = GESTURES[gesture_index]\n",
        "  print(f\"Processing index {gesture_index} for gesture '{gesture}'.\")\n",
        "\n",
        "\n",
        "  # got rid of the delimiter as the file is not tab separated \"delimiter='\\t'\"\n",
        "  df = pd.read_csv(\"/content/sample_data/\" + gesture + \".csv\", names = ['aX', 'aY', 'aZ'])\n",
        "  print(f\"Gesture '{gesture}' has {df.shape[0]} total samples\")\n",
        "\n",
        "  window_size = SAMPLES_PER_GESTURE\n",
        "  stride = 80 # step size between windows\n",
        "\n",
        "  num_windows = ((df.shape[0] - window_size) // stride) + 1\n",
        "\n",
        "\n",
        "  # calculate the number of gesture recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
        "\n",
        "  # print(f\"\\tThere are {num_recordings} recordings of the {gesture} gesture.\")\n",
        "\n",
        "  print(f\"\\tCreating {num_windows} windows for the {gesture} gesture.\")\n",
        "\n",
        "  for i in range(num_windows):\n",
        "    start_idx = i * stride\n",
        "    end_idx = start_idx + window_size\n",
        "\n",
        "    # Make sure we don't go beyond the available data\n",
        "    if end_idx <= df.shape[0]:\n",
        "      X = df['aX'][start_idx:end_idx].values\n",
        "      Y = df['aY'][start_idx:end_idx].values\n",
        "      Z = df['aZ'][start_idx:end_idx].values\n",
        "      tensor = np.vstack((X, Y, Z)).transpose()\n",
        "\n",
        "      inputs.append(tensor)\n",
        "      outputs.append(gesture_index)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "\n",
        "mean = np.mean(inputs, axis=0)\n",
        "std = np.std(inputs, axis=0)\n",
        "inputs = (inputs - mean) / std\n",
        "\n",
        "print(f\"{np.min(inputs)=} {np.max(inputs)=}\")\n",
        "\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "# print(\"Data set parsing and preparation complete.\")\n",
        "print(inputs.shape, outputs.shape)\n",
        "\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "print(f\"Total samples before split: {num_inputs}\")\n",
        "\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\", f\"{inputs_train.shape=}, {outputs_train.shape=}\")\n",
        "\n",
        "print(np.unique(outputs_train))  # Should contain multiple classes\n",
        "print(np.unique(outputs_test))   # Should contain multiple classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0dAmZNpBkSB",
        "outputId": "d8033be3-f539-4791-f72d-d4484b275cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version = 2.18.0\n",
            "\n",
            "Processing index 0 for gesture 'running'.\n",
            "Gesture 'running' has 4355 total samples\n",
            "\tCreating 53 windows for the running gesture.\n",
            "Processing index 1 for gesture 'walking'.\n",
            "Gesture 'walking' has 3756 total samples\n",
            "\tCreating 46 windows for the walking gesture.\n",
            "Processing index 2 for gesture 'idle'.\n",
            "Gesture 'idle' has 3550 total samples\n",
            "\tCreating 43 windows for the idle gesture.\n",
            "np.min(inputs)=np.float64(-7.569344763264801) np.max(inputs)=np.float64(5.510077648639506)\n",
            "(142, 125, 3) (142,)\n",
            "Total samples before split: 142\n",
            "Data set randomization and splitting complete. inputs_train.shape=(85, 125, 3), outputs_train.shape=(85,)\n",
            "[0 1 2]\n",
            "[0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=inputs_train.shape[1:], name='input'),\n",
        "    # tf.keras.layers.Conv1D(8, 4, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=1e-4)),\n",
        "    # tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.GlobalMaxPool1D(data_format='channels_last', name='global_max_pooling1d'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "tQ7ZcyvvNx1j",
        "outputId": "6e7d16ff-dfbf-4e69-be35-99dd94a6b2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ global_max_pooling1d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m99\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ global_max_pooling1d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m227\u001b[0m (908.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227</span> (908.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m227\u001b[0m (908.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227</span> (908.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=inputs_train,\n",
        "    y=outputs_train,\n",
        "    validation_data=[inputs_validate, outputs_validate],\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    epochs=25\n",
        ")"
      ],
      "metadata": {
        "id": "EaQdmxC5N4uE",
        "outputId": "99c0fd8d-e465-4aaa-8fe0-d7b07e5e9522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 278ms/step - accuracy: 0.4461 - loss: 0.8982 - val_accuracy: 0.3793 - val_loss: 0.9429\n",
            "Epoch 2/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.4461 - loss: 0.8420 - val_accuracy: 0.3793 - val_loss: 0.9100\n",
            "Epoch 3/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4872 - loss: 0.8030 - val_accuracy: 0.3793 - val_loss: 0.8801\n",
            "Epoch 4/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5342 - loss: 0.7710 - val_accuracy: 0.4483 - val_loss: 0.8546\n",
            "Epoch 5/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5225 - loss: 0.7431 - val_accuracy: 0.4483 - val_loss: 0.8325\n",
            "Epoch 6/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6125 - loss: 0.7171 - val_accuracy: 0.5172 - val_loss: 0.8123\n",
            "Epoch 7/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6282 - loss: 0.6916 - val_accuracy: 0.6207 - val_loss: 0.7935\n",
            "Epoch 8/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.6751 - loss: 0.6662 - val_accuracy: 0.6207 - val_loss: 0.7760\n",
            "Epoch 9/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7280 - loss: 0.6420 - val_accuracy: 0.6207 - val_loss: 0.7604\n",
            "Epoch 10/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7632 - loss: 0.6197 - val_accuracy: 0.6207 - val_loss: 0.7467\n",
            "Epoch 11/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.7789 - loss: 0.5994 - val_accuracy: 0.7241 - val_loss: 0.7344\n",
            "Epoch 12/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.8024 - loss: 0.5805 - val_accuracy: 0.7586 - val_loss: 0.7233\n",
            "Epoch 13/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8396 - loss: 0.5628 - val_accuracy: 0.7586 - val_loss: 0.7125\n",
            "Epoch 14/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.8767 - loss: 0.5462 - val_accuracy: 0.7586 - val_loss: 0.7032\n",
            "Epoch 15/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8924 - loss: 0.5304 - val_accuracy: 0.7586 - val_loss: 0.6950\n",
            "Epoch 16/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8924 - loss: 0.5152 - val_accuracy: 0.8276 - val_loss: 0.6872\n",
            "Epoch 17/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8924 - loss: 0.5004 - val_accuracy: 0.8621 - val_loss: 0.6796\n",
            "Epoch 18/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8826 - loss: 0.4861 - val_accuracy: 0.8621 - val_loss: 0.6713\n",
            "Epoch 19/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8826 - loss: 0.4719 - val_accuracy: 0.8621 - val_loss: 0.6625\n",
            "Epoch 20/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8826 - loss: 0.4579 - val_accuracy: 0.8621 - val_loss: 0.6538\n",
            "Epoch 21/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8826 - loss: 0.4438 - val_accuracy: 0.8621 - val_loss: 0.6462\n",
            "Epoch 22/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8924 - loss: 0.4311 - val_accuracy: 0.8621 - val_loss: 0.6404\n",
            "Epoch 23/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9100 - loss: 0.4195 - val_accuracy: 0.8621 - val_loss: 0.6358\n",
            "Epoch 24/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8924 - loss: 0.4086 - val_accuracy: 0.8966 - val_loss: 0.6313\n",
            "Epoch 25/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9022 - loss: 0.3981 - val_accuracy: 0.8966 - val_loss: 0.6284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model_quantized.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "9b3Ct1vCXF5i",
        "outputId": "cd053e82-ad1f-45a9-e23a-70c5179fb4d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmp4aoct2bh'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 125, 3), dtype=tf.float32, name='input')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134264332588560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134264332588176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134264332590096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134264332589712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved artifact at '/tmp/tmp5mm9txxt'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 125, 3), dtype=tf.float32, name='input')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134264332588560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134264332588176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134264332590096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134264332589712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2912"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model_quantized.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgRGHV0w-4Cw",
        "outputId": "6a3f4bd4-08e0-4fd0-9578-5efadd799213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header file, model.h, is 17,992 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ]
        }
      ]
    }
  ]
}